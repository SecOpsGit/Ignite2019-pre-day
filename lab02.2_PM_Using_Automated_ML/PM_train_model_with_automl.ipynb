{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Classification using Automated ML\n\nIn this example we use Azure ML's Automated ML functionality to improve on the classifier we built earlier. Automated ML handles the task of building many models from a wide variety of algorithms and choosing a good set of hyper-parameters for them. We then select best model (or one that meets our criteria) and deploy it as a web service."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load and prepare experiment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As part of the setup we have already created an AML workspace. Let's load the workspace and create an experiment."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\nimport logging\nimport os\nimport random\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport pandas as pd\nfrom sklearn import datasets\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\nimport azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.run import AutoMLRun",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We load the workspace directly from the config file we created in the early part of the course."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "home_dir = '..' #os.path.expanduser('~')\nconfig_path = os.path.join(home_dir, 'aml_config')\nws = Workspace.from_config(path=os.path.join(config_path, 'config.json'))\n\nexperiment_name =  'pred-maint-automl' # choose a name for experiment\nproject_folder = '.' # project folder\n\nexperiment=Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data=output, index=['']).T",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Experiment Name</th>\n      <td>pred-maint-automl</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>westus2</td>\n    </tr>\n    <tr>\n      <th>Project Directory</th>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>wopauli_AD</td>\n    </tr>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.2</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>5be49961-ea44-42ec-8021-b728be90d58c</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>myADworkspace</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                       \nExperiment Name    pred-maint-automl                   \nLocation           westus2                             \nProject Directory  .                                   \nResource Group     wopauli_AD                          \nSDK version        1.0.2                               \nSubscription ID    5be49961-ea44-42ec-8021-b728be90d58c\nWorkspace          myADworkspace                       "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Opt in for diagnostics for better experience, quality, and security of future releases:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.telemetry import set_diagnostics_collection\nset_diagnostics_collection(send_diagnostics=True)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Instantiate config file"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now instantiate a `AutoMLConfig` object. This defines the settings and data used to run the experiment.\n\n|Property|Description|\n|-|-|\n|**task**|classification or regression|\n|**primary_metric**|This is the metric that you want to optimize.<br> Classification supports the following primary metrics <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>balanced_accuracy</i><br><i>average_precision_score_weighted</i><br><i>precision_score_weighted</i>|\n|**max_time_sec**|Time limit in seconds for each iterations|\n|**iterations**|Number of iterations. In each iteration Auto ML trains the data with a specific pipeline|\n|**n_cross_validations**|Number of cross validation splits|\n|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n|**y**|(sparse) array-like, shape = [n_samples, ], [n_samples, n_classes]<br>Multi-class targets. An indicator matrix turns on multilabel classification.  This should be an array of integers. |\n|**path**|Relative path to the project folder.  AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder. |"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\n\nprint(\"SDK Version:\", azureml.core.VERSION)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK Version: 1.0.2\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%store -r X_train\n%store -r X_test\n%store -r y_train\n%store -r y_test",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>volt_ma_3</th>\n      <th>rotate_ma_3</th>\n      <th>pressure_ma_3</th>\n      <th>vibration_ma_3</th>\n      <th>volt_sd_3</th>\n      <th>rotate_sd_3</th>\n      <th>pressure_sd_3</th>\n      <th>vibration_sd_3</th>\n      <th>volt_ma_12</th>\n      <th>rotate_ma_12</th>\n      <th>...</th>\n      <th>m_4</th>\n      <th>dm_1</th>\n      <th>dm_2</th>\n      <th>dm_3</th>\n      <th>dm_4</th>\n      <th>df_1</th>\n      <th>df_2</th>\n      <th>df_3</th>\n      <th>df_4</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>170.028993</td>\n      <td>449.533798</td>\n      <td>94.592122</td>\n      <td>40.893502</td>\n      <td>6.721032</td>\n      <td>67.849599</td>\n      <td>18.934956</td>\n      <td>5.874970</td>\n      <td>166.967614</td>\n      <td>429.934546</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>164.192565</td>\n      <td>403.949857</td>\n      <td>105.687417</td>\n      <td>34.255891</td>\n      <td>7.596570</td>\n      <td>50.120452</td>\n      <td>8.555032</td>\n      <td>7.662229</td>\n      <td>166.967614</td>\n      <td>429.934546</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>168.134445</td>\n      <td>435.781707</td>\n      <td>107.793709</td>\n      <td>41.239405</td>\n      <td>10.124584</td>\n      <td>55.084734</td>\n      <td>5.909721</td>\n      <td>5.169304</td>\n      <td>166.967614</td>\n      <td>429.934546</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>165.514453</td>\n      <td>430.472823</td>\n      <td>101.703289</td>\n      <td>40.373739</td>\n      <td>4.673269</td>\n      <td>42.047278</td>\n      <td>4.554047</td>\n      <td>2.106108</td>\n      <td>166.967614</td>\n      <td>429.934546</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>168.809347</td>\n      <td>437.111120</td>\n      <td>90.911060</td>\n      <td>41.738542</td>\n      <td>14.752132</td>\n      <td>47.048609</td>\n      <td>4.244158</td>\n      <td>2.207884</td>\n      <td>166.662702</td>\n      <td>426.828877</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>",
            "text/plain": "    volt_ma_3  rotate_ma_3  pressure_ma_3  vibration_ma_3  volt_sd_3  \\\n0  170.028993  449.533798   94.592122      40.893502       6.721032    \n1  164.192565  403.949857   105.687417     34.255891       7.596570    \n2  168.134445  435.781707   107.793709     41.239405       10.124584   \n3  165.514453  430.472823   101.703289     40.373739       4.673269    \n4  168.809347  437.111120   90.911060      41.738542       14.752132   \n\n   rotate_sd_3  pressure_sd_3  vibration_sd_3  volt_ma_12  rotate_ma_12 ...   \\\n0  67.849599    18.934956      5.874970        166.967614  429.934546   ...    \n1  50.120452    8.555032       7.662229        166.967614  429.934546   ...    \n2  55.084734    5.909721       5.169304        166.967614  429.934546   ...    \n3  42.047278    4.554047       2.106108        166.967614  429.934546   ...    \n4  47.048609    4.244158       2.207884        166.662702  426.828877   ...    \n\n   m_4  dm_1  dm_2  dm_3  dm_4  df_1  df_2  df_3  df_4  age  \n0  1.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   18   \n1  0.0  3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   18   \n2  0.0  6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   18   \n3  0.0  9.0   9.0   9.0   9.0   9.0   9.0   9.0   9.0   18   \n4  0.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0  18   \n\n[5 rows x 37 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train.head()",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_1</th>\n      <th>y_2</th>\n      <th>y_3</th>\n      <th>y_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   y_1  y_2  y_3  y_4\n0  0    0    0    0  \n1  0    0    0    0  \n2  0    0    0    0  \n3  0    0    0    0  \n4  0    0    0    0  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here are the metrics we can choose to optimize our model over."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "azureml.train.automl.constants.Metric.CLASSIFICATION_PRIMARY_SET",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "{'AUC_weighted',\n 'accuracy',\n 'average_precision_score_weighted',\n 'norm_macro_recall',\n 'precision_score_weighted'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now set up a configuration file for the automated ML training experiment. It contains details for how the experiment should run."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_config = AutoMLConfig(task='classification', \n                             preprocess=False,\n                             name=experiment_name,\n                             debug_log='automl_errors.log',\n                             primary_metric='AUC_weighted',\n                             iteration_timeout_minutes=20,\n                             iterations=10,\n                             n_cross_validations=2,\n                             verbosity=logging.INFO,\n                             X = X_train.values, # we convert from pandas to numpy arrays using .vaules\n                             y = y_train.values[:, 0], # we convert from pandas to numpy arrays using .vaules\n                             path=project_folder, )",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Run training experiment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can call the submit method on the experiment object and pass the run configuration. For Local runs the execution is synchronous. Depending on the data and number of iterations this can run for while.\nYou will see the currently running iterations printing to the console."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run = experiment.submit(automl_config, show_output=True)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Parent Run ID: AutoML_b6940271-d95d-4ede-a3f0-0b33a2fb786b\n*******************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n*******************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         0   ",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "--- Logging error ---\nTraceback (most recent call last):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_systemusage_telemetry.py\", line 207, in _get_usage\n    self._log_memory_usage(child_res.ru_maxrss, prefix_message + 'child ')\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'str'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/logging/handlers.py\", line 71, in emit\n    if self.shouldRollover(record):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/logging/handlers.py\", line 188, in shouldRollover\n    self.stream.seek(0, 2)  #due to non-posix-compliant Windows feature\nFileNotFoundError: [Errno 2] No such file or directory\nCall stack:\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/threading.py\", line 884, in _bootstrap\n    self._bootstrap_inner()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/threading.py\", line 1182, in run\n    self.function(*self.args, **self.kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_timer_utilities.py\", line 37, in _run\n    self.callback(*self.args, **self.kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_systemusage_telemetry.py\", line 212, in _get_usage\n    self.logger.info(e)\nMessage: TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'str'\",)\nArguments: ()\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "MaxAbsScaler LightGBM                          0:03:19       0.9905    0.9905\n         1   StandardScalerWrapper LightGBM                 0:02:12       0.9860    0.9905\n         2   ",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "--- Logging error ---\nTraceback (most recent call last):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/logging/handlers.py\", line 71, in emit\n    if self.shouldRollover(record):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/logging/handlers.py\", line 188, in shouldRollover\n    self.stream.seek(0, 2)  #due to non-posix-compliant Windows feature\nFileNotFoundError: [Errno 2] No such file or directory\nCall stack:\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/gen.py\", line 1152, in inner\n    self.run()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/gen.py\", line 1069, in run\n    yielded = self.gen.send(value)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-8f1b381405b2>\", line 1, in <module>\n    local_run = experiment.submit(automl_config, show_output=True)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/core/experiment.py\", line 141, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\", line 46, in _automl_static_submit\n    show_output=show_output)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_azureautomlclient.py\", line 287, in fit\n    existing_run=existing_run, sample_weight_valid=sample_weight_valid)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_azureautomlclient.py\", line 566, in _fit_local\n    transformed_data_context=transformed_data_context)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_azureautomlclient.py\", line 634, in _fit_iteration\n    elapsed_time=elapsed_time\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/automl.py\", line 357, in fit_pipeline\n    is_sending_telemetry=automl_settings.send_telemetry\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_systemusage_telemetry.py\", line 97, in send_usage_telemetry_log\n    self._get_usage(prefix_message)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_systemusage_telemetry.py\", line 206, in _get_usage\n    self._log_memory_usage(res.ru_maxrss, prefix_message)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/azureml/train/automl/_systemusage_telemetry.py\", line 72, in _log_memory_usage\n    self.logger.info(\"{}memory usage {}\".format(prefix_message, mem_usage), extra=extra_info)\nMessage: '[RunId:AutoML_b6940271-d95d-4ede-a3f0-0b33a2fb786b_2][Starting fit_pipeline]memory usage 1044568'\nArguments: ()\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "                                               0:13:34          nan    0.9905\nERROR: 'fitted_pipeline'                               \n         3   ",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run.cancel()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Retrieve the Best Model\n\nBelow we select the best pipeline from our iterations. The *get_output* method on automl_classifier returns the best run and the fitted model for the last *fit* invocation. There are overloads on *get_output* that allow you to retrieve the best run and fitted model for *any* logged metric or a particular *iteration*."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = local_run.get_output()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fitted_model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see from the above results that `StandardScalerWrapper` was used to scale the features and a `LightGBMClassifier` was chosen as the best model based on the metric we defined. This of course does NOT automatically also make it the best model in production, but choosing the right model for production is beyond the scope of this course so we will not address it here."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Hands-on lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-info\">\nUncomment and run the following cell and go to the link provided under Details Page. This links will take us to the Azure portal. Examine the content of the page. Can you find what resource group this resource is under? What kind of resource is it?\n</div>"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# best_run",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-info\">\nIn addition to choosing a good algorithm, the experiment also tuned hyper-parameters. So our model didn't just run with the default hyper-parameter values. Find out how we can get the chosen hyper-parameters from the `fitted_model` object. Describe the hyper-parameters you see. Which ones do you think are the most critical ones?\n</div>"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# write solution here",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### End of lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Manually train selected model (optional - only as a sanity check)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "With the following Python snippet, we can take the information above and store the hyper-parameters for the chosen scaler and chosen model into separate dictionaries we call `scaler_params` and `model_params`."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import re\n\nparams = re.findall(r\"StandardScalerWrapper__\\w+\", \" \".join(fitted_model.get_params().keys()))\nvals = [fitted_model.get_params()[k] for k in params]\nkeys = [re.split(\"__\", p)[1] for p in params]\n\nscaler_params = {k:v for k,v in zip(keys, vals)}\n\nparams = re.findall(r\"LightGBMClassifier__\\w+\", \" \".join(fitted_model.get_params().keys()))\nvals = [fitted_model.get_params()[k] for k in params]\nkeys = [re.split(\"__\", p)[1] for p in params]\n\nmodel_params = {k:v for k,v in zip(keys, vals)}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Hands-on lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-info\">\nLet's now re-create the model that we found above by passing the parameters directly to the scaler and the algorithm. We already have our model, so there's no need to do this other than as a sanity check. Train a `LightGBMClassifier` (using `model_params`) after using `StandardScaler` (with `scaler_params`) to rescale the data. You can do both in a single line of code by using `Pipeline`. Please add your code to the chunk below:\n</div>"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom azureml.train.automl.model_wrappers import LightGBMClassifier\n\n## YOUR CODE GOES HERE (manual_model = Pipeline(...))\n\n## YOUR CODE GOES HERE (train the model on the data)\n## YOUR CODE GOES HERE (score the test data with the trained model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %cat ../solutions/train_manually.py",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-info\">\nWe saw in the above code snippet how we can re-create the same model that automated ML gave us. Print the confusion matrix to see counts for correct classifications and mis-classified examples.\n</div>"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %cat ../solutions/confusion_matrix_y1.py",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### End of lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Score and evaluate the chosen model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the last section we recreated the model generated by the automated ML experiment. This was just a sanity check to make sure that we get the same model. To see that we do, let's now just pick the best model returned by the experiment and use it to get predictions for the test data. This is simply done by replacing `manual_model.predict` with `fitted_model.predict`."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = fitted_model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We should get the same confusion matrix we did in the section above."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "confusion_matrix(y_test.values[:, 0], y_pred)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We use `classification_report` to automatically calculate precision, recall, and the F-1 score from the confusion matrix above."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "cl_report = classification_report(y_test.values[:, 0], y_pred)\nprint(cl_report)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The AUC is just the area under the ROC curve shown here:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import auc, roc_curve\nfpr, tpr, thresholds = roc_curve(y_test.values[:, 0], y_pred)\nroc_auc = auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.plot(fpr, tpr, 'b', label = 'AUC = {0:.2f}'.format(roc_auc))\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Register fitted model for deployment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we have a model we're happy with, we register it to our Azure ML account. This will be the first step toward model management and deployment, which we cover in the next Notebook. Registered models can also be loaded into other workspaces."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "description = 'automated ML PdM (predict y_1)'\ntags = None\nmodel = local_run.register_model(description=description, tags=tags)\nlocal_run.model_id # Use this id to deploy the model as a web service in Azur",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Optionally, we can also take the model and save it on disk as a pickle file, as shown here:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.externals import joblib\njoblib.dump(value=fitted_model, filename='model.pkl')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Hands-on lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-info\">\nSo far we used automated ML to automatically train a classification model for only one of the four failure types, namely `y_1`. Write a loop to use automated ML to train, score and evaluate and finally register a classification model for `y_2`, `y_3` and `y_4`. In each case, compare the evaluation metrics we obtain to the ones we obtained in the previous Notebook when we hand-trained a model.\n</div>"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "all_output = {'y_1': {'local_run': local_run, 'model': model, 'cl_report': cl_report}}\n\nfor i in range(1, 4): ## loop over each target class\n    print(\"Running automl on y_\" + str(i+1))\n    ## YOUR CODE GOES HERE (modify the config file to point to the right target class)\n    ## YOUR CODE GOES HERE (submit the automated ML experiment)\n    ## YOUR CODE GOES HERE (extract the best model)\n    ## YOUR CODE GOES HERE (predict on the test data)\n    ## YOUR CODE GOES HERE (find the classification report for the best model and add it to y_report)\n    ## YOUR CODE GOES HERE (add results to all_output)\n    ## YOUR CODE GOES HERE (register the final model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# %cat ../solutions/automl_loop.py",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "all_output",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-info\">\nNOTE: We can use automated ML to directly train a multi-class classification model instead of training many binary classification models. We will explore that in another Notebook.\n</div>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### End of lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# The end"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}