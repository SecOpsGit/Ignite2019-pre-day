{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "bf74d2e9-2708-49b1-934b-e0ede342f475"
        }
      },
      "cell_type": "markdown",
      "source": "# Machine Learning Experimentation with AML Compute\n\n## Introduction\n\n### Recap\n\nIn the previous notebooks we developed a solution for online anomaly detection.  \n- We implemented an algorithm for calculating running averages of sensor data online, rather than batch.\n- We also tried to determine how many recent sensory readings we need store, so that our algorithm can still identify seasonal and linear trends.  \n\nThese improvements to the batch solution for AD saved both time and space.  \n\nTo test whether the resulting online version worked as well as the original batch soution (which can be considered the *ground truth*), we used a test script (`sample_run.py`) that compared the performance of the two solutions. \n\n\n### Goals\n\nIn the previous lab, we ran our test script manually with different parameters to see how well our online solution compared to the original batch solution.\n\nIn this lab, we will develop a more sophisticated approach to optimizing our online solution, leveraging AML SDK tools for *Machine Learning experimentation* that allow us to log model performance.\n\nYou will learn:\n- How to define a remote `AmlCompute` compute target for ML Experimentation on Azure\n- How to configure this compute target for auto scaling, so you only pay for computing resources you are using\n- How to modify your analysis script, so that you can run it on AmlCompute\n- How to investigate the run history to determine which hyperparameters settings in your analysis script gave you the best results."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Getting started\n\nLet's get started. First let's import some Python libraries."
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "c377ea0c-0cd9-4345-9be2-e20fb29c94c3"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# %matplotlib inline\n\nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "edaa7f2f-2439-4148-b57a-8c794c0945ec"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml\nfrom azureml.core import Workspace, Run\n\n# check core SDK version number\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Azure ML SDK Version:  1.0.6\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Diagnostics\nOpt-in diagnostics for better experience, quality, and security of future releases."
    },
    {
      "metadata": {
        "tags": [
          "Diagnostics"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.telemetry import set_diagnostics_collection\nset_diagnostics_collection(send_diagnostics=True)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Turning diagnostics collection on. \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Initialize workspace\nInitialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.workspace import Workspace\n\n# If you are on Azure Databricks, use this\n# config_path = '/dbfs/tmp/'\n\n# If you are running this on Jupyter, you may want to run \n# config_path = os.path.expanduser('~')\nconfig_path = '..'\n\nws = Workspace.from_config(path=os.path.join(config_path, 'aml_config','config.json'))\n\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\nWorkspace name: myADworkspace\nAzure region: westus2\nSubscription id: 5be49961-ea44-42ec-8021-b728be90d58c\nResource group: wopauli_AD\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "59f52294-4a25-4c92-bab8-3b07f0f44d15"
        }
      },
      "cell_type": "markdown",
      "source": "## Create an Azure ML experiment\nLet's create an experiment named \"ADMLExp\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "bc70f780-c240-4779-96f3-bc5ef9a37d59"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment\n\nscript_folder = 'scripts'\n\nos.makedirs(script_folder, exist_ok=True)\n\nexp = Experiment(workspace=ws, name='ADMLExp')",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "nbpresent": {
          "id": "defe921f-8097-44c3-8336-8af6700804a7"
        }
      },
      "cell_type": "markdown",
      "source": "## Download telemetry dataset\nIn order to test on the telemetry dataset we will first need to download it from Yan LeCun's web site directly and save them in a `data` folder locally."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport urllib\n\ndata_path = os.path.join(config_path, 'data')\nos.makedirs(data_path, exist_ok=True)\n\ncontainer = 'https://sethmottstore.blob.core.windows.net/predmaint/'\n\nurllib.request.urlretrieve(container + 'telemetry.csv', filename=os.path.join(data_path, 'telemetry.csv'))\nurllib.request.urlretrieve(container + 'anoms.csv', filename=os.path.join(data_path, 'anoms.csv'))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "('../data/anoms.csv', <http.client.HTTPMessage at 0x7efd498af320>)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Upload dataset to default datastore \nA [datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data) is a place where data can be stored that is then made accessible to a Run either by means of mounting or copying the data to the compute target. A datastore can either be backed by an Azure Blob Storage or and Azure File Share (ADLS will be supported in the future). For simple data handling, each workspace provides a default datastore that can be used, in case the data is not already in Blob Storage or File Share.\n\nIn this next step, we will upload the training and test set into the workspace's default datastore, which we will then later be mount on a Batch AI cluster for training."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ds = ws.get_default_datastore()\nds.upload(src_dir=data_path, target_path='telemetry', overwrite=True, show_progress=True)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Uploading ../data/anoms.csv\nUploading ../data/failures.csv\nUploading ../data/machines.csv\nUploading ../data/maintenance.csv\nUploading ../data/telemetry.csv\nUploaded ../data/machines.csv, 1 files out of an estimated total of 5\nUploaded ../data/failures.csv, 2 files out of an estimated total of 5\nUploaded ../data/maintenance.csv, 3 files out of an estimated total of 5\nUploaded ../data/anoms.csv, 4 files out of an estimated total of 5\nUploaded ../data/telemetry.csv, 5 files out of an estimated total of 5\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_d46375d1e41d47468eb9a4ea61e724bb"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create Batch AI cluster as compute target\n[Batch AI](https://docs.microsoft.com/en-us/azure/batch-ai/overview) is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Batch AI cluster in the current workspace, if it doesn't already exist. We will then run the training script on this compute target."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If we could not find the cluster with the given name in the previous cell, then we will create a new cluster here. We will create a AmlCompute Cluster of `Standard_DS3_v2` CPU VMs. This process is broken down into 3 steps:\n1. create the configuration (this step is local and only takes a second)\n2. create the Batch AI cluster (this step will take about **20 seconds**)\n3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell\n\n> Pay close attention to the `provisioning_configuration` below! We can configure our compute target such that it auto-scales, and if we set the minimum number of nodes to zero, we won't be paying anything for the compute while we are not using it."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "help(azureml.core.compute.AmlCompute)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Help on class AmlCompute in module azureml.core.compute.amlcompute:\n\nclass AmlCompute(azureml.core.compute.compute.ComputeTarget)\n |  Class for managing AmlCompute target objects.\n |  \n |  Method resolution order:\n |      AmlCompute\n |      azureml.core.compute.compute.ComputeTarget\n |      abc.ABC\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  delete(self)\n |      Removes the AmlCompute object from its associated workspace.\n |      \n |      .. remarks::\n |          If this object was created through Azure ML,\n |          the corresponding cloud based objects will also be deleted. If this object was created externally and only\n |          attached to the workspace, it will raise exception and nothing will be changed.\n |      \n |      :raises: ComputeTargetException\n |  \n |  detach(self)\n |      Detach is not supported for AmlCompute object. Try to use delete instead.\n |      \n |      :raises: ComputeTargetException\n |  \n |  get(self)\n |      Returns compute object\n |  \n |  get_status(self)\n |      Retrieves the current detailed status for the AmlCompute cluster.\n |      \n |      :return: A detailed status object for the cluster\n |      :rtype: AmlComputeStatus\n |  \n |  refresh_state(self)\n |      Perform an in-place update of the properties of the object based on the current state of the\n |      corresponding cloud object. Primarily useful for manual polling of compute state.\n |  \n |  serialize(self)\n |      Convert this AmlCompute object into a json serialized dictionary.\n |      \n |      :return: The json representation of this AmlCompute object\n |      :rtype: dict\n |  \n |  update(self, min_nodes=None, max_nodes=None, idle_seconds_before_scaledown=None)\n |      Update Scale settings for AmlCompute target\n |      \n |      :param min_nodes: Minimum number of nodes to use on the cluster.\n |      :type min_nodes: int\n |      :param max_nodes: Maximum number of nodes to use on the cluster\n |      :type max_nodes: int\n |      :param idle_seconds_before_scaledown: Node idle time in seconds before scaling down the cluster\n |      :type idle_seconds_before_scaledown: int\n |  \n |  wait_for_completion(self, show_output=False, min_node_count=None, timeout_in_minutes=20)\n |      Wait for the AmlCompute cluster to finish provisioning. This can be configured to wait for a minimum number of\n |      nodes, and to timeout after a set period of time.\n |      \n |      :param show_output: Boolean to provide more verbose output\n |      :type show_output: bool\n |      :param min_node_count: Minimum number of nodes to wait for before considering provisioning to be complete. This\n |          doesn't have to equal the minimum number of nodes that the compute was provisioned with, however it should\n |          not be greater than that.\n |      :type min_node_count: int\n |      :param timeout_in_minutes: The duration in minutes to wait before considering provisioning to have failed.\n |      :type timeout_in_minutes: int\n |      :raises: ComputeTargetException\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  deserialize(workspace, object_dict)\n |      Convert a json object into a AmlCompute object. Will fail if the provided workspace is not the workspace\n |      the Compute is associated with.\n |      \n |      :param workspace: The workspace object the AmlCompute object is associated with\n |      :type workspace: azureml.core.workspace.Workspace\n |      :param object_dict: A json object to convert to a AmlCompute object\n |      :type object_dict: dict\n |      :return: The AmlCompute representation of the provided json object\n |      :rtype: AmlCompute\n |      :raises: ComputeTargetException\n |  \n |  provisioning_configuration(vm_size='', vm_priority='dedicated', min_nodes=0, max_nodes=None, idle_seconds_before_scaledown=None, vnet_resourcegroup_name=None, vnet_name=None, subnet_name=None, tags=None, description=None)\n |      Create a configuration object for provisioning an AmlCompute target\n |      \n |      :param vm_size: Size of agent VMs. More details can be found here: https://aka.ms/azureml-vm-details.\n |          Note that not all sizes are available in all regions, as\n |          detailed in the previous link.\n |      :type vm_size: str\n |      :param vm_priority: dedicated or lowpriority VMs. If not specified, will default to dedicated.\n |      :type vm_priority: str\n |      :param min_nodes: Minimum number of nodes to use on the cluster. If not specified, will default to 0.\n |      :type min_nodes: int\n |      :param max_nodes: Maximum number of nodes to use on the cluster\n |      :type max_nodes: int\n |      :param idle_seconds_before_scaledown: Node idle time in seconds before scaling down the cluster\n |      :type idle_seconds_before_scaledown: int\n |      :param vnet_resourcegroup_name: Name of the resource group where the virtual network is located\n |      :type vnet_resourcegroup_name: str\n |      :param vnet_name: Name of the virtual network\n |      :type vnet_name: str\n |      :param subnet_name: Name of the subnet inside the vnet\n |      :type subnet_name: str\n |      :param tags: A dictionary of key value tags to provide to the compute object\n |      :type tags: dict[str, str]\n |      :param description: A description to provide to the compute object\n |      :type description: str\n |      :return: A configuration object to be used when creating a Compute object\n |      :rtype: AmlComputeProvisioningConfiguration\n |      :raises: ComputeTargetException\n |  \n |  supported_vmsizes(workspace, location=None)\n |      List the supported VM sizes in a region.\n |      \n |      :param workspace:\n |      :type workspace: azureml.core.workspace.Workspace\n |      :param location: Location of cluster. If not specified, will default to workspace location.\n |      :type location: str\n |      :return: List of supported VM sizes in a region with name of the VM, VCPUs, RAM\n |      :rtype: list[dict]\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from azureml.core.compute.compute.ComputeTarget:\n |  \n |  __init__(self, workspace, name)\n |      ComputeTarget constructor retrieves a cloud representation of a Compute object associated with the\n |      provided workspace. Returns an instance of a child class corresponding to the specific type of the\n |      retrieved Compute object.\n |      \n |      :param workspace: The workspace object containing the Compute object to retrieve\n |      :type workspace: azureml.core.workspace.Workspace\n |      :param name: The name of the of the Compute object to retrieve\n |      :type name: str\n |      :return: An instance of a child of ComputeTarget corresponding to the specific type of the retrieved\n |          Compute object\n |      :rtype: ComputeTarget\n |      :raises: ComputeTargetException\n |  \n |  ----------------------------------------------------------------------\n |  Static methods inherited from azureml.core.compute.compute.ComputeTarget:\n |  \n |  __new__(cls, workspace, name)\n |      ComputeTarget constructor is used to retrieve a cloud representation of a Compute object associated with the\n |      provided workspace. Will return an instance of a child class corresponding to the specific type of the\n |      retrieved Compute object.\n |      \n |      :param workspace: The workspace object containing the Compute object to retrieve\n |      :type workspace: azureml.core.workspace.Workspace\n |      :param name: The name of the of the Compute object to retrieve\n |      :type name: str\n |      :return: An instance of a child of ComputeTarget corresponding to the specific type of the retrieved\n |          Compute object\n |      :rtype: ComputeTarget\n |      :raises: ComputeTargetException\n |  \n |  attach(workspace, name, attach_configuration)\n |      Attach a Compute object associated with the provided workspace. The type of object to attach is\n |      determined based on the provided attached configuration.\n |      \n |      :param workspace: The workspace object to attach the Compute object to.\n |      :type workspace: azureml.core.workspace.Workspace\n |      :param name: The name to associate with the Compute object\n |      :type name: str\n |      :param attach_configuration: A ComputeTargetAttachConfiguration object that is used to determine\n |          the type of Compute object to attach, and how to configure it.\n |      :type attach_configuration: ComputeTargetAttachConfiguration\n |      :return: An instance of a child of ComputeTarget corresponding to the type of object attached\n |      :rtype: ComputeTarget\n |      :raises: ComputeTargetException\n |  \n |  create(workspace, name, provisioning_configuration)\n |      Provisions a Compute object associated with the provided workspace.\n |      \n |      .. remarks::\n |          The type of object provisioned is\n |          determined based on the provided provisioning configuration.\n |      \n |      :param workspace: The workspace object to create the Compute object under.\n |      :type workspace: azureml.core.workspace.Workspace\n |      :param name: The name to associate with the Compute object\n |      :type name: str\n |      :param provisioning_configuration: A ComputeTargetProvisioningConfiguration object that is used to determine\n |          the type of Compute object to provision, and how to configure it.\n |      :type provisioning_configuration: ComputeTargetProvisioningConfiguration\n |      :return: An instance of a child of ComputeTarget corresponding to the type of object provisioned\n |      :rtype: ComputeTarget\n |      :raises: ComputeTargetException\n |  \n |  list(workspace)\n |      List all ComputeTarget objects within the workspace. Will return a list of instantiated child objects\n |      corresponding to the specific type of Compute.\n |      \n |      :param workspace: The workspace object containing the objects to list\n |      :type workspace: azureml.core.workspace.Workspace\n |      :return: List of compute targets within the workspace\n |      :rtype: list[azureml.core.compute.ComputeTarget]\n |      :raises: ComputeTargetException\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from abc.ABC:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\n\n# choose a name for your cluster\ncluster_name = \"ADPMAmlCompute\"\n\ntry:\n    # look for the existing cluster by name\n    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n    if type(compute_target) is AmlCompute:\n        print('Found existing compute target {}.'.format(cluster_name))\n    else:\n        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(cluster_name))\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    compute_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_DS3_v2\",\n                                                               idle_seconds_before_scaledown=1800,\n                                                               min_nodes=0, \n                                                               max_nodes=4)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n    \n    # can poll for a minimum number of nodes and for a specific timeout. \n    # if no min node count is provided it uses the scale settings for the cluster\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n    \n    # Use the 'status' property to get a detailed status for the current cluster. \n    print(compute_target.status.serialize())",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found existing compute target ADPMAmlCompute.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create an Execution script for Azure ML experimentation\n\n### Azure ML concepts  \n\nPlease note the following three things in the code below:\n1. The script accepts arguments using the argparse package. In this case there is one argument `--data_folder` which specifies the file system folder in which the script can find the telemetry data\n```\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data_folder')\n```\n2. The script is accessing the Azure ML `Run` object by executing `run = Run.get_context()`. Further down the script is using the `run` to report the F2 score for a given choice of `window_size`.\n```\n    run.log('fbeta_score', np.float(score))\n```\n3. When running the script on Azure ML, you can write files out to a folder `./outputs` that is relative to the root directory. This folder is specially tracked by Azure ML in the sense that any files written to that folder during script execution on the remote target will be picked up by Run History; these files (known as artifacts) will be available as part of the run history record.\n\n### Hands-on Lab: Adopt the execution script\n\nIn order for you to be able to use HyperDrive and AmlCompute, we have to modify the script from the previous notebook in several ways.  \n\nThe main adoptions are:\n1. The handling of input arguments (e.g. the hyperparameter `window_size` that we are interested in).  \n2. We log the results rather than to return them as a function output.  For this purpose, we use the `context` of our Azure ML [Run](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.run?view=azure-ml-py) object, which allows us to log our results.\n\n*Instructions:*\n\nWe have done most of the heavy lifting for you in this regard, but left two exercises for you:\n1. Modify the `main` function, so that it also parses the `n_epochs` argument to the execution script.\n2. Modify the `sample_run` function, so that it also logs the `fbeta_score` to the `context` of our `Run`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# %%writefile scripts/sample_run_AmlCompute.py\n\n# Copyright (c) Microsoft Corporation. All rights reserved.\n# Licensed under the MIT License.\n\n\"\"\"\n\nThis script was modified from the sample_run function of lab 1.2, such that it can be run on AmlCompute.\n\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import fbeta_score\nimport os\nimport time\n\nfrom pyculiarity import detect_ts\n\nfrom azureml.core import Run\n\nimport argparse # for parsing input arguments\n\ndef running_avg(ts, com=6):\n    rm_o = np.zeros_like(ts)\n    rm_o[0] = ts[0]\n    \n    for r in range(1, len(ts)):\n        curr_com = float(min(com, r))\n        rm_o[r] = rm_o[r-1] + (ts[r] - rm_o[r-1])/(curr_com + 1)\n    \n    return rm_o\n\n\ndef detect_ts_online(df_smooth, window_size, stop):\n    is_anomaly = False\n    run_time = 9999\n    start_index = max(0, stop - window_size)\n    df_win = df_smooth.iloc[start_index:stop, :]\n    start_time = time.time()\n    results = detect_ts(df_win, alpha=0.05, max_anoms=0.02, only_last=None, longterm=False, e_value=False, direction='both')\n    run_time = time.time() - start_time\n    if results['anoms'].shape[0] > 0:\n        timestamp = df_win['timestamp'].tail(1).values[0]\n        if timestamp == results['anoms'].tail(1)['timestamp'].values[0]:\n            is_anomaly = True\n    return is_anomaly, run_time\n\n\ndef sample_run(df, anoms_batch, run, window_size = 500, com = 12, n_epochs=10):\n\n    # create arrays that will hold the results of batch AD (y_true) and online AD (y_pred)\n    y_true = [False] * n_epochs\n    y_pred = [True] * n_epochs\n    run_times = []\n\n    # check which unique machines, sensors, and timestamps we have in the dataset\n    machineIDs = df['machineID'].unique()\n    sensors = df.columns[2:]\n    timestamps = df['datetime'].unique()[window_size:]\n\n    # sample n_machines_test random machines and sensors \n    random_machines = np.random.choice(machineIDs, n_epochs)\n    random_sensors = np.random.choice(sensors, n_epochs)\n\n    # we intialize an array with that will later hold a sample of timetamps\n    random_timestamps = np.random.choice(timestamps, n_epochs)\n\n    for i in range(0, n_epochs):\n        # take a slice of the dataframe that only contains the measures of one random machine\n        df_s = df[df['machineID'] == random_machines[i]]\n        \n        # smooth the values of one random sensor, using our run_avg function\n        smooth_values = running_avg(df_s[random_sensors[i]].values, com)\n\n        # create a data frame with two columns: timestamp, and smoothed values\n        df_smooth = pd.DataFrame(data={'timestamp': df_s['datetime'].values, 'value': smooth_values})\n\n        # load the results of batch AD for this machine and sensor\n        anoms_s = anoms_batch[((anoms_batch['machineID'] == random_machines[i]) & (anoms_batch['errorID'] == random_sensors[i]))]\n\n        # only do anomaly detection online, if the batch solution actually found an anomaly\n        if anoms_s.shape[0] > 0:\n            # Let's make sure we have at least one anomaly in our sample! Otherwise it doesn't make sense to calculate\n            # any performance metric.  We can just use the timestamp of the last anomalys\n            if i == 0:\n                anoms_timestamps = anoms_s['datetime'].values\n                random_timestamps[i] = anoms_timestamps[-1:][0]\n\n            # select the row of the test case\n            test_case = df_smooth[df_smooth['timestamp'] == random_timestamps[i]]\n            test_case_index = test_case.index.values[0]\n\n            # check whether the batch AD found an anomaly at that time stamps and copy into y_true at idx\n            y_true_i = random_timestamps[i] in anoms_s['datetime'].values\n\n            # perform online AD, and write result to y_pred\n            y_pred_i, run_times_i = detect_ts_online(df_smooth, window_size, test_case_index)\n        else:\n            y_pred_i, y_true_i = 0, 0\n        \n        y_true[i] = y_true_i\n        y_pred[i] = y_pred_i\n        run_times.append(run_times_i)\n        \n        score = np.float(fbeta_score(y_true, y_pred, beta=2))\n        print(\"fbeta_score: %s\" % round(score, 2))\n        \n        run.log('run_time', np.mean(run_times))\n        run.log(<your solution for logging the fbeta_score goes here>)\n        \n    run.log('final_fbeta_score', np.float(score))\n\n        \ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n    parser.add_argument('--window_size', type=int, dest='window_size', default=100, help='window size')\n    parser.add_argument('--com', type=int, dest='com', default=12, help='Specify decay in terms of center of mass for running avg')\n    parser.add_argument(<your solution for handinling the n_epochs parameter goes here>)\n    args = parser.parse_args()\n\n    data_folder = os.path.join(args.data_folder, 'telemetry')\n    window_size = args.window_size\n    com = args.com\n    n_epochs = args.n_epochs\n    \n    # start an Azure ML run\n    run = Run.get_context()\n\n    print(\"Reading data ... \", end=\"\")\n    df = pd.read_csv(os.path.join(data_folder, 'telemetry.csv'))\n    print(\"Done.\")\n\n    print(\"Parsing datetime...\", end=\"\")\n    df['datetime'] = pd.to_datetime(df['datetime'], format=\"%m/%d/%Y %I:%M:%S %p\")\n    print(\"Done.\")\n    \n    print(\"Reading data ... \", end=\"\")\n    anoms_batch = pd.read_csv(os.path.join(data_folder, 'anoms.csv'))\n    anoms_batch['datetime'] = pd.to_datetime(anoms_batch['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n    print(\"Done.\")\n\n    print('Dataset is stored here: ', data_folder)\n\n    sample_run(df, anoms_batch, run, window_size, com, n_epochs)\n\n    \nif __name__== \"__main__\":\n      main()\n",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "usage: __main__.py [-h] [--data-folder DATA_FOLDER]\n                   [--window_size WINDOW_SIZE] [--com COM]\n                   [--n_epochs N_EPOCHS]\n__main__.py: error: unrecognized arguments: -f /home/nbuser/.local/share/jupyter/runtime/kernel-3d9b45c4-dbcd-4069-878b-0462e4101786.json\n",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Save your solution\n\nOnce you are done making those changes, you can uncomment the first line of the above cell, and execute the cell so that your solution is saved.\n\n## End of Hands-on Lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Copy the test script into the script folder\n\nThe next step is to copy the script to the staging folder for your ML Experiment."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from shutil import copyfile\n\ncopyfile('../solutions/sample_run_AmlCompute.py', os.path.join(script_folder,'sample_run_AmlCompute.py'))",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "'scripts/sample_run_AmlCompute.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create an AzureML training Estimator\n\nNext, we construct an `azureml.train.estimator.Estimator` estimator object, use the Batch AI cluster as compute target, and pass the mount-point of the datastore to the training code as a parameter. The azureml.train module contains several estimators.  Here we use `Estimator`, because it is the most general one of all of them, but if you used e.g. `PyTorch`, you could use an estimator for that ([see AML SDK documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.dnn.pytorch?view=azure-ml-py)). \n\nThe estimator is providing a simple way of launching a custom job on a compute target.  It will automatically provide a docker image, if additional pip or conda packages are required, their names can be passed in via the `pip_packages` and `conda_packages` arguments and they will be included in the resulting docker.\n\nIn our case, we will need to install the following `pip_packages`: `numpy`, `pandas`, `scikit-learn`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.estimator import Estimator\n\n# input arguments to the script\nscript_params = {\n    '--data-folder': ws.get_default_datastore().as_mount(),\n    '--window_size': 500,\n    '--n_epochs': 1000,\n    '--com': 12\n}\n\nest = Estimator(source_directory=script_folder, # this is the folder where you saved the sample_run script\n                 script_params=script_params, # these are the input arguments ot the script\n                 compute_target=compute_target, # the name of the compute target you created above\n                 entry_script='sample_run_AmlCompute.py',\n                 pip_packages=['numpy','pandas','scikit-learn','pyculiarity'])",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Submit job to run\nCalling the `fit` function on the estimator submits the job to Azure ML for execution. Submitting the job should only take a few seconds."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run = exp.submit(config=est)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Monitor the Run\nAs the Run is executed, it will go through the following stages:\n1. Preparing: A docker image is created matching the Python environment specified by the estimator and it will be uploaded to the workspace's Azure Container Registry. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs.  Creating and uploading the image takes about **5 minutes**. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n\n2. Scaling: If the compute needs to be scaled up (i.e. the Batch AI cluster requires more nodes to execute the run than currently available), the Batch AI cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about **5 minutes**.\n\n3. Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the `entry_script` is executed. While the job is running, stdout and the `./logs` folder are streamed to the run history and can be viewed to monitor the progress of the run.\n\n4. Post-Processing: The `./outputs` folder of the run is copied over to the run history\n\nWe can periodically check the status of the run object, and navigate to Azure portal to monitor the run."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>ADMLExp</td><td>ADMLExp_1547664508693</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/5be49961-ea44-42ec-8021-b728be90d58c/resourceGroups/wopauli_AD/providers/Microsoft.MachineLearningServices/workspaces/myADworkspace/experiments/ADMLExp/runs/ADMLExp_1547664508693\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: ADMLExp,\nId: ADMLExp_1547664508693,\nType: azureml.scriptrun,\nStatus: Queued)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n### Widget for Monitoring Runs\n\nThe widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n\nNote: The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show() ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2871e1f89cfd453cb9c7d0002f01a357",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Hands-on Lab: Explore AML workspace on the Azure Portal\n\nWhen you are running this for the first time, the job will take a while to prepare, because the AmlCompute target has to be fully provisioned first.  You can seize this opportunity to become familiar with the Azure Portal.\n\nTry to find the following items and explore them\n- ML workspace in the portal (make sure you use the one you created and save to config.json)\n- Experiments, and run objects\n- Compute Targets\n- Look at the log files for the job you have submitted. These can be very helpful for monitoring progress and troubleshooting.\n\n### End of Lab\n\nYou can run the following command if you want this notebook to not continue until the run is completed. (not necessary)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# run.wait_for_completion(show_output = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### The Run object\n\nThe Run object provides the interface to the run history - both to the job and to the control plane (this notebook), and both while the job is running and after it has completed. It provides a number of interesting features for instance:\n* `run.get_details()`: Provides a rich set of properties of the run\n* `run.get_metrics()`: Provides a dictionary with all the metrics that were reported for the Run\n* `run.get_file_names()`: List all the files that were uploaded to the run history for this Run. This will include the `outputs` and `logs` folder, azureml-logs and other logs, as well as files that were explicitly uploaded to the run using `run.upload_file()`\n\nBelow are some examples -- please run through them and inspect their output."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.get_details()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.get_metrics()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.get_file_names()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Plot accuracy over epochs\nSince we can retrieve the metrics from the run, we can easily make plots using `matplotlib` in the notebook. Then we can add the plotted image to the run using `run.log_image()`, so all information about the run is kept together."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nos.makedirs('./imgs', exist_ok = True)\nmetrics = run.get_metrics()\n\nplt.close()\nplt.figure(figsize = (13,5))\nplt.plot(metrics['fbeta_score'])\nplt.xlabel('epochs', fontsize = 14)\nplt.ylabel('fbeta score', fontsize = 14)\nplt.title('Fbeta Score over Epochs', fontsize = 16)\nrun.log_image(name = 'fbeta_score_over_epochs', plot = plt)\ndisplay()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Hands-on lab\n\nThe goal of this lab is to have you become comfortable with ML model experimentation:\n- Running your model with different parameters\n- Investigating the results in the Azure portal\n\n### Instructions:\n1. Try different settings for the `script_params` above\n  - Change the `script_params` settings\n  - Execute the cell to update the `Estimator`\n  - `submit` the updated `Estimator` as a new `Run` in your ML `Experiment`\n2. After you have submitted a couple of different runs, go into the Azure portal to explore the results\n3. Try to figure out which of the runs had the best preformance.\n\n## End Lab"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Clean up\n\nAt this point we could delete the compute target. But remember if you set the `cluster_min_nodes` value to 0 when you created the cluster, once the jobs are finished, all nodes are deleted automatically. So you don't have to delete the cluster itself since it won't incur any cost. Next time you submit jobs to it, the cluster will then automatically \"grow\" up to the `cluster_min_nodes` which is set to 4.\n\nAlso, if you are planning to take the next lab on Hyperdrive, you will be using the same compute target again."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# # Are you sure you want to delete the compute target?\n# compute_target.delete()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Hyper Parameter Tuning with HyperDrive and AmlCompute (fka BatchAI)\n\nIn the next lab, we will show you how to use BatchAI to do this tedious labor for you!\n\nIf you want to, you can already read up on HyperDrive:\n- [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)\n- [sample notebook](https://github.com/Azure/MachineLearningNotebooks/tree/master/training/03.train-hyperparameter-tune-deploy-with-tensorflow)"
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "name": "AD_machine_learning_experimentation",
    "nbpresent": {
      "slides": {
        "05bb34ad-74b0-42b3-9654-8357d1ba9c99": {
          "id": "05bb34ad-74b0-42b3-9654-8357d1ba9c99",
          "prev": "851089af-9725-40c9-8f0b-9bf892b2b1fe",
          "regions": {
            "23fb396d-50f9-4770-adb3-0d6abcb40767": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "2039d2d5-aca6-4f25-a12f-df9ae6529cae",
                "part": "whole"
              },
              "id": "23fb396d-50f9-4770-adb3-0d6abcb40767"
            }
          }
        },
        "11bebe14-d1dc-476d-a31a-5828b9c3adf0": {
          "id": "11bebe14-d1dc-476d-a31a-5828b9c3adf0",
          "prev": "502648cb-26fe-496b-899f-84c8fe1dcbc0",
          "regions": {
            "a42499db-623e-4414-bea2-ff3617fd8fc5": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "4788c040-27a2-4dc1-8ed0-378a99b3a255",
                "part": "whole"
              },
              "id": "a42499db-623e-4414-bea2-ff3617fd8fc5"
            }
          }
        },
        "134f92d0-6389-4226-af51-1134ae8e8278": {
          "id": "134f92d0-6389-4226-af51-1134ae8e8278",
          "prev": "36b8728c-32ad-4941-be03-5cef51cdc430",
          "regions": {
            "b6d82a77-2d58-4b9e-a375-3103214b826c": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "7ab0e6d0-1f1c-451b-8ac5-687da44a8287",
                "part": "whole"
              },
              "id": "b6d82a77-2d58-4b9e-a375-3103214b826c"
            }
          }
        },
        "282a2421-697b-4fd0-9485-755abf5a0c18": {
          "id": "282a2421-697b-4fd0-9485-755abf5a0c18",
          "prev": "a8b9ceb9-b38f-4489-84df-b644c6fe28f2",
          "regions": {
            "522fec96-abe7-4a34-bd34-633733afecc8": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "d58e7785-c2ee-4a45-8e3d-4c538bf8075a",
                "part": "whole"
              },
              "id": "522fec96-abe7-4a34-bd34-633733afecc8"
            }
          }
        },
        "2dfec088-8a70-411a-9199-904ef3fa2383": {
          "id": "2dfec088-8a70-411a-9199-904ef3fa2383",
          "prev": "282a2421-697b-4fd0-9485-755abf5a0c18",
          "regions": {
            "0535fcb6-3a2b-4b46-98a7-3ebb1a38c47e": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "c377ea0c-0cd9-4345-9be2-e20fb29c94c3",
                "part": "whole"
              },
              "id": "0535fcb6-3a2b-4b46-98a7-3ebb1a38c47e"
            }
          }
        },
        "36a814c9-c540-4a6d-92d9-c03553d3d2c2": {
          "id": "36a814c9-c540-4a6d-92d9-c03553d3d2c2",
          "prev": "b52e4d09-5186-44e5-84db-3371c087acde",
          "regions": {
            "8bfba503-9907-43f0-b1a6-46a0b4311793": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "d5e4a56c-dfac-4346-be83-1c15b503deac",
                "part": "whole"
              },
              "id": "8bfba503-9907-43f0-b1a6-46a0b4311793"
            }
          }
        },
        "36b8728c-32ad-4941-be03-5cef51cdc430": {
          "id": "36b8728c-32ad-4941-be03-5cef51cdc430",
          "prev": "05bb34ad-74b0-42b3-9654-8357d1ba9c99",
          "regions": {
            "a36a5bdf-7f62-49b0-8634-e155a98851dc": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "e33dfc47-e7df-4623-a7a6-ab6bcf944629",
                "part": "whole"
              },
              "id": "a36a5bdf-7f62-49b0-8634-e155a98851dc"
            }
          }
        },
        "3f136f2a-f14c-4a4b-afea-13380556a79c": {
          "id": "3f136f2a-f14c-4a4b-afea-13380556a79c",
          "prev": "54cb8dfd-a89c-4922-867b-3c87d8b67cd3",
          "regions": {
            "80ecf237-d1b0-401e-83d2-6d04b7fcebd3": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "7debeb2b-ecea-414f-9b50-49657abb3e6a",
                "part": "whole"
              },
              "id": "80ecf237-d1b0-401e-83d2-6d04b7fcebd3"
            }
          }
        },
        "502648cb-26fe-496b-899f-84c8fe1dcbc0": {
          "id": "502648cb-26fe-496b-899f-84c8fe1dcbc0",
          "prev": "3f136f2a-f14c-4a4b-afea-13380556a79c",
          "regions": {
            "4c83bb4d-2a52-41ba-a77f-0c6efebd83a6": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "dbd22f6b-6d49-4005-b8fe-422ef8ef1d42",
                "part": "whole"
              },
              "id": "4c83bb4d-2a52-41ba-a77f-0c6efebd83a6"
            }
          }
        },
        "54cb8dfd-a89c-4922-867b-3c87d8b67cd3": {
          "id": "54cb8dfd-a89c-4922-867b-3c87d8b67cd3",
          "prev": "aa224267-f885-4c0c-95af-7bacfcc186d9",
          "regions": {
            "0848f0a7-032d-46c7-b35c-bfb69c83f961": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "3c32c557-d0e8-4bb3-a61a-aa51a767cd4e",
                "part": "whole"
              },
              "id": "0848f0a7-032d-46c7-b35c-bfb69c83f961"
            }
          }
        },
        "636b563c-faee-4c9e-a6a3-f46a905bfa82": {
          "id": "636b563c-faee-4c9e-a6a3-f46a905bfa82",
          "prev": "c5f59b98-a227-4344-9d6d-03abdd01c6aa",
          "regions": {
            "9c64f662-05dc-4b14-9cdc-d450b96f4368": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "70640ac0-7041-47a8-9a7f-e871defd74b2",
                "part": "whole"
              },
              "id": "9c64f662-05dc-4b14-9cdc-d450b96f4368"
            }
          }
        },
        "793cec2f-8413-484d-aa1e-388fd2b53a45": {
          "id": "793cec2f-8413-484d-aa1e-388fd2b53a45",
          "prev": "c66f3dfd-2d27-482b-be78-10ba733e826b",
          "regions": {
            "d08f9cfa-3b8d-4fb4-91ba-82d9858ea93e": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "dd56113e-e3db-41ae-91b7-2472ed194308",
                "part": "whole"
              },
              "id": "d08f9cfa-3b8d-4fb4-91ba-82d9858ea93e"
            }
          }
        },
        "83e912ff-260a-4391-8a12-331aba098506": {
          "id": "83e912ff-260a-4391-8a12-331aba098506",
          "prev": "fe5a0732-69f5-462a-8af6-851f84a9fdec",
          "regions": {
            "2fefcf5f-ea20-4604-a528-5e6c91bcb100": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "c3f2f57c-7454-4d3e-b38d-b0946cf066ea",
                "part": "whole"
              },
              "id": "2fefcf5f-ea20-4604-a528-5e6c91bcb100"
            }
          }
        },
        "851089af-9725-40c9-8f0b-9bf892b2b1fe": {
          "id": "851089af-9725-40c9-8f0b-9bf892b2b1fe",
          "prev": "636b563c-faee-4c9e-a6a3-f46a905bfa82",
          "regions": {
            "31c9dda5-fdf4-45e2-bcb7-12aa0f30e1d8": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "8408b90e-6cdd-44d1-86d3-648c23f877ac",
                "part": "whole"
              },
              "id": "31c9dda5-fdf4-45e2-bcb7-12aa0f30e1d8"
            }
          }
        },
        "87ab653d-e804-470f-bde9-c67caaa0f354": {
          "id": "87ab653d-e804-470f-bde9-c67caaa0f354",
          "prev": "a8c2d446-caee-42c8-886a-ed98f4935d78",
          "regions": {
            "bc3aeb56-c465-4868-a1ea-2de82584de98": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "59f52294-4a25-4c92-bab8-3b07f0f44d15",
                "part": "whole"
              },
              "id": "bc3aeb56-c465-4868-a1ea-2de82584de98"
            }
          }
        },
        "8b887c97-83bc-4395-83ac-f6703cbe243d": {
          "id": "8b887c97-83bc-4395-83ac-f6703cbe243d",
          "prev": "36a814c9-c540-4a6d-92d9-c03553d3d2c2",
          "regions": {
            "9d0bc72a-cb13-483f-a572-2bf60d0d145f": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "75499c85-d0a1-43db-8244-25778b9b2736",
                "part": "whole"
              },
              "id": "9d0bc72a-cb13-483f-a572-2bf60d0d145f"
            }
          }
        },
        "a8b9ceb9-b38f-4489-84df-b644c6fe28f2": {
          "id": "a8b9ceb9-b38f-4489-84df-b644c6fe28f2",
          "prev": null,
          "regions": {
            "f741ed94-3f24-4427-b615-3ab8753e5814": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "bf74d2e9-2708-49b1-934b-e0ede342f475",
                "part": "whole"
              },
              "id": "f741ed94-3f24-4427-b615-3ab8753e5814"
            }
          }
        },
        "a8c2d446-caee-42c8-886a-ed98f4935d78": {
          "id": "a8c2d446-caee-42c8-886a-ed98f4935d78",
          "prev": "2dfec088-8a70-411a-9199-904ef3fa2383",
          "regions": {
            "f03457d8-b2a7-4e14-9a73-cab80c5b815d": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "edaa7f2f-2439-4148-b57a-8c794c0945ec",
                "part": "whole"
              },
              "id": "f03457d8-b2a7-4e14-9a73-cab80c5b815d"
            }
          }
        },
        "aa224267-f885-4c0c-95af-7bacfcc186d9": {
          "id": "aa224267-f885-4c0c-95af-7bacfcc186d9",
          "prev": "793cec2f-8413-484d-aa1e-388fd2b53a45",
          "regions": {
            "0d7ac442-5e1d-49a5-91b3-1432d72449d8": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "4d6826fe-2cb8-4468-85ed-a242a1ce7155",
                "part": "whole"
              },
              "id": "0d7ac442-5e1d-49a5-91b3-1432d72449d8"
            }
          }
        },
        "b52e4d09-5186-44e5-84db-3371c087acde": {
          "id": "b52e4d09-5186-44e5-84db-3371c087acde",
          "prev": "134f92d0-6389-4226-af51-1134ae8e8278",
          "regions": {
            "7af7d997-80b2-497d-bced-ef8341763439": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "376882ec-d469-4fad-9462-18e4bbea64ca",
                "part": "whole"
              },
              "id": "7af7d997-80b2-497d-bced-ef8341763439"
            }
          }
        },
        "c5f59b98-a227-4344-9d6d-03abdd01c6aa": {
          "id": "c5f59b98-a227-4344-9d6d-03abdd01c6aa",
          "prev": "83e912ff-260a-4391-8a12-331aba098506",
          "regions": {
            "7268abff-0540-4c06-aefc-c386410c0953": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "396d478b-34aa-4afa-9898-cdce8222a516",
                "part": "whole"
              },
              "id": "7268abff-0540-4c06-aefc-c386410c0953"
            }
          }
        },
        "c66f3dfd-2d27-482b-be78-10ba733e826b": {
          "id": "c66f3dfd-2d27-482b-be78-10ba733e826b",
          "prev": "8b887c97-83bc-4395-83ac-f6703cbe243d",
          "regions": {
            "6cbe8e0e-8645-41a1-8a38-e44acb81be4b": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "7594c7c7-b808-48f7-9500-d7830a07968a",
                "part": "whole"
              },
              "id": "6cbe8e0e-8645-41a1-8a38-e44acb81be4b"
            }
          }
        },
        "d22045e5-7e3e-452e-bc7b-c6c4a893da8e": {
          "id": "d22045e5-7e3e-452e-bc7b-c6c4a893da8e",
          "prev": "ec41f96a-63a3-4825-9295-f4657a440ddb",
          "regions": {
            "24e2a3a9-bf65-4dab-927f-0bf6ffbe581d": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "defe921f-8097-44c3-8336-8af6700804a7",
                "part": "whole"
              },
              "id": "24e2a3a9-bf65-4dab-927f-0bf6ffbe581d"
            }
          }
        },
        "d24c958c-e419-4e4d-aa9c-d228a8ca55e4": {
          "id": "d24c958c-e419-4e4d-aa9c-d228a8ca55e4",
          "prev": "11bebe14-d1dc-476d-a31a-5828b9c3adf0",
          "regions": {
            "25312144-9faa-4680-bb8e-6307ea71370f": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "bed09a92-9a7a-473b-9464-90e479883a3e",
                "part": "whole"
              },
              "id": "25312144-9faa-4680-bb8e-6307ea71370f"
            }
          }
        },
        "ec41f96a-63a3-4825-9295-f4657a440ddb": {
          "id": "ec41f96a-63a3-4825-9295-f4657a440ddb",
          "prev": "87ab653d-e804-470f-bde9-c67caaa0f354",
          "regions": {
            "22e8be98-c254-4d04-b0e4-b9b5ae46eefe": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "bc70f780-c240-4779-96f3-bc5ef9a37d59",
                "part": "whole"
              },
              "id": "22e8be98-c254-4d04-b0e4-b9b5ae46eefe"
            }
          }
        },
        "fe5a0732-69f5-462a-8af6-851f84a9fdec": {
          "id": "fe5a0732-69f5-462a-8af6-851f84a9fdec",
          "prev": "d22045e5-7e3e-452e-bc7b-c6c4a893da8e",
          "regions": {
            "671b89f5-fa9c-4bc1-bdeb-6e0a4ce8939b": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "fd46e2ab-4ab6-4001-b536-1f323525d7d3",
                "part": "whole"
              },
              "id": "671b89f5-fa9c-4bc1-bdeb-6e0a4ce8939b"
            }
          }
        }
      },
      "themes": {}
    },
    "notebookId": 1951564739234010
  },
  "nbformat": 4,
  "nbformat_minor": 1
}