{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps are documented [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-create-your-first-pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Experiment, Workspace, Run, Datastore, Dataset\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.train.sklearn import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path = 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace = ws, name = \"house_prices_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.upload(src_dir = \"./data\", target_path = \"data\", overwrite = True, show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob_input_data = DataReference(\n",
    "#     datastore = def_blob_store,\n",
    "#     data_reference_name = \"input_data\",\n",
    "#     path_on_datastore = \"data/ames.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = PipelineData(\n",
    "    \"output_data\",\n",
    "    datastore = def_blob_store,\n",
    "    output_name = \"output_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = \"compute02\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace = ws, name = cluster_name)\n",
    "    print(\"Found existing compute target\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_DS3_V2\", \n",
    "                                                           max_nodes = 6)\n",
    "\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output = True, min_node_count = None, \n",
    "                                       timeout_in_minutes = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat scripts/train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = \"./scripts\"\n",
    "\n",
    "script_params = {\n",
    "    \"--data-folder\": ds.as_mount()\n",
    "}\n",
    "\n",
    "train_step = SKLearn(source_directory = script_folder, \n",
    "                     compute_target = compute_target,\n",
    "                     entry_script = \"train_model.py\",\n",
    "                     script_params = script_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_run = exp.submit(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list of steps to run\n",
    "# pipeline_steps = [train_step, score_step]\n",
    "\n",
    "# from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# # Build the pipeline\n",
    "# pipeline = Pipeline(workspace = ws, steps = [pipeline_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core import Experiment\n",
    "\n",
    "# # Submit the pipeline to be run\n",
    "# pipeline_run = exp.submit(pipeline)\n",
    "# pipeline_run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline1 = pipeline_run1.publish_pipeline(\n",
    "#      name = \"My_Published_Pipeline\",\n",
    "#      description = \"My Published Pipeline Description\",\n",
    "#      version = \"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import PublishedPipeline\n",
    "# import requests\n",
    "\n",
    "# response = requests.post(published_pipeline1.endpoint,\n",
    "#                          headers = aad_token,\n",
    "#                          json = {\"ExperimentName\": \"My_Pipeline\",\n",
    "#                                \"ParameterAssignments\": {\"pipeline_arg\": 20}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
